//Network buffers
   MessageBuffer * n_RequestFromL1Cache, network="To", virtual_network="3",
        vnet_type="request";
   MessageBuffer * n_RequestToL1Cache, network="From", virtual_network="3",
        vnet_type="request";
   
   MessageBuffer * n_ResponseFromL1Cache, network="To", virtual_network="4",
        vnet_type="response";
   MessageBuffer * n_ResponseToL1Cache, network="From", virtual_network="4",
        vnet_type="response";

--

Events
//Neibour search
N_Search, desc="Intercore request or response";
N_Not_Valid, desc="Not valid";
N_Fwd_GET_INSTR, desc="GET_INSTR from other processor";
N_DataL1, desc="Data from other cache";
N_SendL2, desc="Check l2";

out_port(requestL1Network_out, RequestMsg, requestFromL1Cache);
out_port(responseL1Network_out, ResponseMsg, responseFromL1Cache);
out_port(unblockNetwork_out, ResponseMsg, unblockFromL1Cache);
out_port(optionalQueue_out, RubyRequest, optionalQueue);

//Network_out
out_port(n_RequestL1Network_out, RequestMsg, n_RequestFromL1Cache);
out_port(n_ResponseL1Network_out, ResponseMsg, n_ResponseFromL1Cache);

 in_port(optionalQueue_in, RubyRequest, optionalQueue, desc="...", rank = 5) {
      DPRINTF(Custom,"optionalQueue_in\n");
      if (optionalQueue_in.isReady(clockEdge())) {
          peek(optionalQueue_in, RubyRequest) {
              // Instruction Prefetch
              if (in_msg.Type == RubyRequestType:IFETCH) {
                  DPRINTF(Custom,"I Prefetch\n");
                  Entry L1Icache_entry := getL1ICacheEntry(in_msg.LineAddress);
                  if (is_valid(L1Icache_entry)) {
                      // The block to be prefetched is already present in the
                      // cache. We should drop this request.
                      trigger(prefetch_request_type_to_event(in_msg.Type),
                              in_msg.LineAddress,
                              L1Icache_entry, TBEs[in_msg.LineAddress]);
                  }

                  // Check to see if it is in the OTHER L1
                  Entry L1Dcache_entry := getL1DCacheEntry(in_msg.LineAddress);
                  if (is_valid(L1Dcache_entry)) {
                      // The block is in the wrong L1 cache. We should drop
                      // this request.
                      trigger(prefetch_request_type_to_event(in_msg.Type),
                              in_msg.LineAddress,
                              L1Dcache_entry, TBEs[in_msg.LineAddress]);
                  }

                  if (L1Icache.cacheAvail(in_msg.LineAddress)) {
                      // L1 does't have the line, but we have space for it
                      // in the L1 so let's see if the L2 has it
                      trigger(prefetch_request_type_to_event(in_msg.Type),
                              in_msg.LineAddress,
                              L1Icache_entry, TBEs[in_msg.LineAddress]);
                  } else {
                      // No room in the L1, so we need to make room in the L1
                      Addr victim := L1Icache.cacheProbe(in_msg.LineAddress);
                      trigger(Event:PF_L1_Replacement,
                              victim, getL1ICacheEntry(victim), TBEs[victim]);
                  }
              } else {
                  // Data prefetch
                  DPRINTF(Custom,"D Prefetch\n");
                  Entry L1Dcache_entry := getL1DCacheEntry(in_msg.LineAddress);
                  if (is_valid(L1Dcache_entry)) {
                      // The block to be prefetched is already present in the
                      // cache. We should drop this request.
                      trigger(prefetch_request_type_to_event(in_msg.Type),
                              in_msg.LineAddress,
                              L1Dcache_entry, TBEs[in_msg.LineAddress]);
                  }

                  // Check to see if it is in the OTHER L1
                  Entry L1Icache_entry := getL1ICacheEntry(in_msg.LineAddress);
                  if (is_valid(L1Icache_entry)) {
                      // The block is in the wrong L1. Just drop the prefetch
                      // request.
                      trigger(prefetch_request_type_to_event(in_msg.Type),
                              in_msg.LineAddress,
                              L1Icache_entry, TBEs[in_msg.LineAddress]);
                  }

                  if (L1Dcache.cacheAvail(in_msg.LineAddress)) {
                      // L1 does't have the line, but we have space for it in
                      // the L1 let's see if the L2 has it
                      trigger(prefetch_request_type_to_event(in_msg.Type),
                              in_msg.LineAddress,
                              L1Dcache_entry, TBEs[in_msg.LineAddress]);
                  } else {
                      // No room in the L1, so we need to make room in the L1
                      Addr victim := L1Dcache.cacheProbe(in_msg.LineAddress);
                      trigger(Event:PF_L1_Replacement,
                              victim, getL1DCacheEntry(victim), TBEs[victim]);
                  }
              }
          }
      }
  }

  // Response  from other machines
  in_port(responseL1Network_in, ResponseMsg, responseToL1Cache, rank = 4) {
    DPRINTF(Custom,"responseL1Network_in\n");
    if (responseL1Network_in.isReady(clockEdge())) {
      peek(responseL1Network_in, ResponseMsg, block_on="addr") {
        assert(in_msg.Destination.isElement(machineID));
        

        Entry cache_entry := getCacheEntry(in_msg.addr);
        TBE tbe := TBEs[in_msg.addr];
        if (is_invalid(cache_entry)) {
              DPRINTF(Custom, "Cache entry is invalid for address: %#x\n", in_msg.addr);
              trigger(Event:Ifetch, in_msg.addr,
                      cache_entry, tbe);
        }
        
        DPRINTF(Custom,"State : %s\n",getState(tbe, cache_entry, in_msg.addr));

        if(in_msg.Type == CoherenceResponseType:DATA_EXCLUSIVE) {
          trigger(Event:Data_Exclusive, in_msg.addr, cache_entry, tbe);
        } else if(in_msg.Type == CoherenceResponseType:DATA) {
            DPRINTF(Custom,"DATA -> recv\n");
          if ((getState(tbe, cache_entry, in_msg.addr) == State:IS ||
               getState(tbe, cache_entry, in_msg.addr) == State:IS_I ||
               getState(tbe, cache_entry, in_msg.addr) == State:PF_IS ||
               getState(tbe, cache_entry, in_msg.addr) == State:PF_IS_I) &&
              machineIDToMachineType(in_msg.Sender) == MachineType:L1Cache) {
              DPRINTF(Custom,"DataS_fromL1\n");

              trigger(Event:DataS_fromL1, in_msg.addr, cache_entry, tbe);

          } else if ( (getPendingAcks(tbe) - in_msg.AckCount) == 0 ) {
            DPRINTF(Custom,"Data_all_Acks\n");
            trigger(Event:Data_all_Acks, in_msg.addr, cache_entry, tbe);
          } else {
            DPRINTF(Custom,"Data\n");
            trigger(Event:Data, in_msg.addr, cache_entry, tbe);
          }
        } else if (in_msg.Type == CoherenceResponseType:ACK) {
          if ( (getPendingAcks(tbe) - in_msg.AckCount) == 0 ) {
            trigger(Event:Ack_all, in_msg.addr, cache_entry, tbe);
          } else {
            trigger(Event:Ack, in_msg.addr, cache_entry, tbe);
          }
        } else if (in_msg.Type == CoherenceResponseType:WB_ACK) {
          trigger(Event:WB_Ack, in_msg.addr, cache_entry, tbe);
        } else if(in_msg.Type == CoherenceResponseType:N_NOT) {
          DPRINTF(Custom,"Not available\n");
          trigger(Event:Ifetch, in_msg.addr,
                      cache_entry, tbe);
        }
        else {
          error("Invalid L1 response type");
        }
      }
    }
  }

  // Request from other machines
  in_port(requestL1Network_in, RequestMsg, requestToL1Cache, rank = 3) {
    DPRINTF(Custom,"requestL1Network_in\n");
    if(requestL1Network_in.isReady(clockEdge())) {
      peek(requestL1Network_in, RequestMsg, block_on="addr") {
        assert(in_msg.Destination.isElement(machineID));

        Entry cache_entry := getCacheEntry(in_msg.addr);
        TBE tbe := TBEs[in_msg.addr];
        DPRINTF(Custom,"State type: %s\n",in_msg.Type);

        if (in_msg.Type == CoherenceRequestType:INV) {
          DPRINTF(Custom,"Event : Inv\n");
          trigger(Event:Inv, in_msg.addr, cache_entry, tbe);
        } else if (in_msg.Type == CoherenceRequestType:GETX ||
                   in_msg.Type == CoherenceRequestType:UPGRADE) {
                    DPRINTF(Custom,"Event :Fwd_GETX\n");
          // upgrade transforms to GETX due to race
          trigger(Event:Fwd_GETX, in_msg.addr, cache_entry, tbe);
        } else if (in_msg.Type == CoherenceRequestType:GETS) {
          DPRINTF(Custom,"Event : Fwd_GETS\n");
          trigger(Event:Fwd_GETS, in_msg.addr, cache_entry, tbe);
        } else if (in_msg.Type == CoherenceRequestType:GET_INSTR) {
          trigger(Event:Fwd_GET_INSTR, in_msg.addr, cache_entry, tbe);
          DPRINTF(Custom,"Event : Fwd_GET_INSTR\n");
        } else if (in_msg.Type == CoherenceRequestType:N_GET_INSTR) {
          DPRINTF(Custom,"Event : N_Fwd_GET_INSTR\n");
          if(is_valid(cache_entry)){
            trigger(Event:N_Fwd_GET_INSTR, in_msg.addr, cache_entry, tbe);
          }
          //need to implement
        } else {
          error("Invalid forwarded request type");
        }
      }
    }
  }

  // Response  from other  L1Caches
  in_port(n_ResponseL1Network_in, ResponseMsg, n_ResponseToL1Cache, rank = 2) {
    DPRINTF(Custom,"n_ResponseL1Network_in\n");
    if (n_ResponseL1Network_in.isReady(clockEdge())) {
      peek(n_ResponseL1Network_in, ResponseMsg, block_on="addr") {
        assert(in_msg.Destination.isElement(machineID));
        

        Entry cache_entry := getCacheEntry(in_msg.addr);
        TBE tbe := TBEs[in_msg.addr];
        
        DPRINTF(Custom,"State : %s\n",getState(tbe, cache_entry, in_msg.addr));
        if(is_valid(cache_entry)){
          if(in_msg.Type == CoherenceResponseType:DATA){
            DPRINTF(Custom,"Data recv\n");
            trigger(Event:N_DataL1, in_msg.addr, cache_entry, tbe);
          }
          else{
            DPRINTF(Custom,"Check L2\n");
            trigger(Event:N_SendL2, in_msg.addr, cache_entry, tbe);
          }
        }
        else{
          DPRINTF(Custom,"Not valid in Response");
          error("Invalid forwarded request");
        }


      }
    }
  }

  // Request from other  L1Caches
  in_port(n_RequestL1Network_in, RequestMsg, n_RequestToL1Cache, rank = 1) {
    DPRINTF(Custom,"n_RequestL1Network_in\n");
    if(n_RequestL1Network_in.isReady(clockEdge())) {
      peek(n_RequestL1Network_in, RequestMsg, block_on="addr") {
        assert(in_msg.Destination.isElement(machineID));

        Entry cache_entry := getCacheEntry(in_msg.addr);
        TBE tbe := TBEs[in_msg.addr];
        DPRINTF(Custom,"State type: %s\n",in_msg.Type);

        if (in_msg.Type == CoherenceRequestType:N_GET_INSTR) {
          DPRINTF(Custom,"Event : N_GET_INSTR\n");
          if(is_invalid(cache_entry)){
            DPRINTF(Custom,"Not Valid\n");
            trigger(Event:N_Not_Valid, in_msg.addr, cache_entry, tbe);
          }
          else {
            DPRINTF(Custom,"Valid->avail\n");
            trigger(Event:N_Fwd_GET_INSTR, in_msg.addr, cache_entry, tbe);
          }
        } else {
          error("Invalid forwarded request type");
        }
      }
    }
  }

  // Mandatory Queue betweens Node's CPU and it's L1 caches
  in_port(mandatoryQueue_in, RubyRequest, mandatoryQueue, desc="...", rank = 0) {
    DPRINTF(Custom, "mandatoryQueue_in, Current machine_id : %s\n", machineID);
    DPRINTF(RubySlicc, "mandatoryQueue_in, Current machine_id : %s\n", machineID);
    if (mandatoryQueue_in.isReady(clockEdge())) {
      peek(mandatoryQueue_in, RubyRequest, block_on="LineAddress") {

        // Check for data access to blocks in I-cache and ifetchs to blocks in D-cache

        if (in_msg.Type == RubyRequestType:IFETCH) {
          DPRINTF(Custom, "I access\n");
          // ** INSTRUCTION ACCESS ***

          Entry L1Icache_entry := getL1ICacheEntry(in_msg.LineAddress);
          if (is_valid(L1Icache_entry)) {
            // The tag matches for the L1, so the L1 asks the L2 for it.
            DPRINTF(Custom, "Valid\n");
            trigger(mandatory_request_type_to_event(in_msg.Type), in_msg.LineAddress,
                    L1Icache_entry, TBEs[in_msg.LineAddress]);
          } else {

            // Check to see if it is in the OTHER L1
            Entry L1Dcache_entry := getL1DCacheEntry(in_msg.LineAddress);
            if (is_valid(L1Dcache_entry)) {
              // The block is in the wrong L1, put the request on the queue to the shared L2
              DPRINTF(Custom, "Wrong cache\n");
              trigger(Event:L1_Replacement, in_msg.LineAddress,
                      L1Dcache_entry, TBEs[in_msg.LineAddress]);
            }

            if (L1Icache.cacheAvail(in_msg.LineAddress)) {
              // L1 does't have the line, but we have space for it
              // in the L1 so let's see if the L2 has it.
              DPRINTF(Custom, "Check L2\n");
              DPRINTF(Custom, "Occupancy: %d\n", L1Icache.CacheOccupancy());

              if(L1Icache.CacheOccupancy() != 0){
                trigger(Event:N_Search, in_msg.LineAddress,
                      L1Icache_entry, TBEs[in_msg.LineAddress]);
              }
              else{
                trigger(mandatory_request_type_to_event(in_msg.Type), in_msg.LineAddress,
                      L1Icache_entry, TBEs[in_msg.LineAddress]);
              }
              
              
            } else {
              // No room in the L1, so we need to make room in the L1

              // Check if the line we want to evict is not locked
              DPRINTF(Custom, "Replace\n");
              Addr addr := L1Icache.cacheProbe(in_msg.LineAddress);
              check_on_cache_probe(mandatoryQueue_in, addr);

              trigger(Event:L1_Replacement, addr,
                      getL1ICacheEntry(addr),
                      TBEs[addr]);
            }
          }
        } else {

          // *** DATA ACCESS ***
          DPRINTF(Custom, "D access\n");
          Entry L1Dcache_entry := getL1DCacheEntry(in_msg.LineAddress);
          if (is_valid(L1Dcache_entry)) {
            // The tag matches for the L1, so the L1 ask the L2 for it
            DPRINTF(Custom, "Valid\n");
            trigger(mandatory_request_type_to_event(in_msg.Type), in_msg.LineAddress,
                    L1Dcache_entry, TBEs[in_msg.LineAddress]);
          } else {

            // Check to see if it is in the OTHER L1
            Entry L1Icache_entry := getL1ICacheEntry(in_msg.LineAddress);
            if (is_valid(L1Icache_entry)) {
              DPRINTF(Custom, "Wrong cache\n");
              // The block is in the wrong L1, put the request on the queue to the shared L2
              trigger(Event:L1_Replacement, in_msg.LineAddress,
                      L1Icache_entry, TBEs[in_msg.LineAddress]);
            }

            if (L1Dcache.cacheAvail(in_msg.LineAddress)) {
              // L1 does't have the line, but we have space for it
              // in the L1 let's see if the L2 has it.
              DPRINTF(Custom, "Check L2\n");
              trigger(mandatory_request_type_to_event(in_msg.Type), in_msg.LineAddress,
                      L1Dcache_entry, TBEs[in_msg.LineAddress]);
            } else {
              // No room in the L1, so we need to make room in the L1

              // Check if the line we want to evict is not locked
              DPRINTF(Custom, "Replacement\n");
              Addr addr := L1Dcache.cacheProbe(in_msg.LineAddress);
              check_on_cache_probe(mandatoryQueue_in, addr);

              trigger(Event:L1_Replacement, addr,
                      getL1DCacheEntry(addr),
                      TBEs[addr]);
            }
          }
        }
      }
    }
  }

 // ACTIONS
  action(a_issueGETS, "a", desc="Issue GETS") {
    DPRINTF(Custom, "a_issueGETS : Dest L2\n");
    
      peek(mandatoryQueue_in, RubyRequest) {
        if (in_msg.Type == RubyRequestType:LD){
        enqueue(requestL1Network_out, RequestMsg, l1_request_latency) {
          out_msg.addr := address;
          out_msg.Type := CoherenceRequestType:GETS;
          out_msg.Requestor := machineID;
          out_msg.Destination.add(mapAddressToRange(address, MachineType:L2Cache,
                            l2_select_low_bit, l2_select_num_bits, intToID(0)));
          DPRINTF(RubySlicc, "address: %#x, destination: %s\n",
                  address, out_msg.Destination);
          out_msg.MessageSize := MessageSizeType:Control;
          out_msg.Prefetch := in_msg.Prefetch;
          out_msg.AccessMode := in_msg.AccessMode;
        }
      }
    }
    
  }

  action(pa_issuePfGETS, "pa", desc="Issue prefetch GETS") {
    DPRINTF(Custom, "pa_issuePfGETS, Dest : L2\n");
    peek(optionalQueue_in, RubyRequest) {
      enqueue(requestL1Network_out, RequestMsg, l1_request_latency) {
        out_msg.addr := address;
        out_msg.Type := CoherenceRequestType:GETS;
        out_msg.Requestor := machineID;
        out_msg.Destination.add(mapAddressToRange(address, MachineType:L2Cache,
                          l2_select_low_bit, l2_select_num_bits, intToID(0)));
        DPRINTF(RubySlicc, "address: %#x, destination: %s\n",
                address, out_msg.Destination);
        out_msg.MessageSize := MessageSizeType:Control;
        out_msg.Prefetch := in_msg.Prefetch;
        out_msg.AccessMode := in_msg.AccessMode;
      }
    }
  }

  action(ai_issueGETINSTR, "ai", desc="Issue GETINSTR") {
    DPRINTF(Custom, "ai_issueGETINSTR, Dest : L2\n");
    
      peek(mandatoryQueue_in, RubyRequest) {
        if (in_msg.Type == RubyRequestType:IFETCH){
        enqueue(requestL1Network_out, RequestMsg, l1_request_latency) {
          out_msg.addr := address;
          out_msg.Type := CoherenceRequestType:GET_INSTR;
          out_msg.Requestor := machineID;
          out_msg.Destination.add(mapAddressToRange(address, MachineType:L2Cache,
                            l2_select_low_bit, l2_select_num_bits, intToID(0)));
          DPRINTF(RubySlicc, "address: %#x, destination: %s\n",
                  address, out_msg.Destination);
          out_msg.MessageSize := MessageSizeType:Control;
          out_msg.Prefetch := in_msg.Prefetch;
          out_msg.AccessMode := in_msg.AccessMode;
        }
      }
    }
  }

  //New action
  action(Nai_issueNGETINSTR, "nai", desc="Check other cache") {
    
    NodeID id := machineIDToNodeID(machineID);
    NodeID dest := id;
    int curr := IDToInt(id);

    if(curr == 0){
      dest := intToID(1);
    }
    else{
      dest := intToID(0);
    }

    
    DPRINTF(Custom, "Nai_issueNGETINSTR, Dest : %d\n",dest);
    peek(mandatoryQueue_in, RubyRequest) {
      enqueue(n_RequestL1Network_out, RequestMsg, l1_request_latency) {
        out_msg.addr := address;
        out_msg.Type := CoherenceRequestType:N_GET_INSTR;
        out_msg.Requestor := machineID;
        out_msg.Destination.add(mapNodeIdToMacine(dest, MachineType:L1Cache));
        DPRINTF(RubySlicc, "address: %#x, destination: %s\n",
                address, out_msg.Destination);
        out_msg.MessageSize := MessageSizeType:Control;
        // out_msg.Prefetch := in_msg.Prefetch;
        // out_msg.AccessMode := in_msg.AccessMode;
      }
    }
  }
  //new 
  action(nl_checkL2cache, "nlc", desc="Get from L2 for other cache") {
    NodeID id := machineIDToNodeID(machineID);
    NodeID dest := id;
    int curr := IDToInt(id);

    if(curr == 0){
      dest := intToID(1);
    }
    else{
      dest := intToID(0);
    }
    DPRINTF(Custom, "nl_checkL2cache, Dest : L1\n");
    peek(n_RequestL1Network_in, RequestMsg) {
      enqueue(n_ResponseL1Network_out, ResponseMsg, l1_request_latency) {
        out_msg.addr := address;
        out_msg.Type := CoherenceResponseType:N_NOT;
        out_msg.Sender := machineID;
        out_msg.Destination.add(mapNodeIdToMacine(dest, MachineType:L1Cache));
        DPRINTF(RubySlicc, "address: %#x, destination: %s\n",
                address, out_msg.Destination);
        out_msg.MessageSize := MessageSizeType:Control;
        // out_msg.Prefetch := in_msg.Prefetch;
        // out_msg.AccessMode := in_msg.AccessMode;
      }
    }
  }

 action(c_issueUPGRADE, "c", desc="Issue GETX") {
    DPRINTF(Custom, "c_issueUPGRADE, Dest : L2\n");
    
      peek(mandatoryQueue_in, RubyRequest) {
        if ((in_msg.Type == RubyRequestType:ST) || (in_msg.Type == RubyRequestType:ATOMIC)){
          enqueue(requestL1Network_out, RequestMsg,  l1_request_latency) {
            out_msg.addr := address;
            out_msg.Type := CoherenceRequestType:UPGRADE;
            out_msg.Requestor := machineID;
            out_msg.Destination.add(mapAddressToRange(address, MachineType:L2Cache,
                              l2_select_low_bit, l2_select_num_bits, intToID(0)));
            DPRINTF(RubySlicc, "address: %#x, destination: %s\n",
                    address, out_msg.Destination);
            out_msg.MessageSize := MessageSizeType:Control;
            out_msg.Prefetch := in_msg.Prefetch;
            out_msg.AccessMode := in_msg.AccessMode;
          }
        }
    }
  }

//Required
  action(d_sendDataToRequestor, "d", desc="send data to requestor") {
    DPRINTF(Custom, "d_sendDataToRequestor start\n");
    
    peek(n_RequestL1Network_in, RequestMsg) {
      Entry cache_entry := getCacheEntry(in_msg.addr);

      enqueue(n_ResponseL1Network_out, ResponseMsg, l1_response_latency) {
      assert(is_valid(cache_entry));
      out_msg.addr := address;
      out_msg.Type := CoherenceResponseType:DATA;
      out_msg.Sender := machineID;
      out_msg.Destination.add(in_msg.Requestor);
      out_msg.DataBlk := cache_entry.DataBlk;
      out_msg.MessageSize := MessageSizeType:Response_Data;
      out_msg.AckCount := 0;
      DPRINTF(Custom, "d_sendDataToRequestor, Dest : %s\n",in_msg.Requestor);
    }
      

      
    }
  }
  transition({M,E,S,IS,NP,I}, N_SendL2) {
    pp_allocateL1ICacheBlock;
    // i_allocateTBE;
    ai_issueGETINSTR;
    uu_profileInstMiss;
    po_observeMiss;
    o_popnIncomingResponseQueue;
  }

  //New transition
  transition({NP,I}, N_Search, IS) {
    pp_allocateL1ICacheBlock;
    i_allocateTBE;
    Nai_issueNGETINSTR;
    // ai_issueGETINSTR;
    // uu_profileInstMiss;
    // po_observeMiss;
    k_popMandatoryQueue;
  }

  //New Transistions
  transition({NP, I}, N_Not_Valid) {
    nl_checkL2cache;
    // fi_sendInvAck;
    l_popnRequestQueue;
  }

  transition(S, Store, SM) {
    i_allocateTBE;
    c_issueUPGRADE;
    uu_profileDataMiss;
    k_popMandatoryQueue;
  }
//New transition
  transition({M,E,S,NP,I}, N_Fwd_GET_INSTR) {
    d_sendDataToRequestor;
    // d2_sendDataToL2;
    l_popnRequestQueue;
  }
  


 //New transition
  transition(IS, N_DataL1, S) {
    u_writenDataToL1Cache;
    j_sendUnblock;
    hx_load_hit;
    s_deallocateTBE;
    // e_sendAckToRequestor;
    o_popnIncomingResponseQueue;
    kd_wakeUpDependents;
  }

//New 
  transition(IS_I, N_DataL1, I) {
    u_writenDataToL1Cache;
    j_sendUnblock;
    hx_load_hit;
    s_deallocateTBE;
    // e_sendAckToRequestor;
    o_popnIncomingResponseQueue;
    kd_wakeUpDependents;
  }

